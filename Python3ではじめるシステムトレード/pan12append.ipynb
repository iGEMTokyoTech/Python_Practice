{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#付録12.A: パンローリングのティックデータの呼び込み\n",
    "from datetime import datetime, date,timedelta\n",
    "from datetime import time\n",
    "def yymmdd_split(yymmdd):#日時インデックスから年、月、日に分類する関数\n",
    "    yy=int(yymmdd[:2])+2000\n",
    "    mm=int(yymmdd[2:4])\n",
    "    dd=int(yymmdd[4:6])\n",
    "    return yy,mm,dd\n",
    "\n",
    "import os\n",
    "def dir_file_get(path,date1,date0):#指定されたフォルダーにあるファイル名を取得\n",
    "    list=os.listdir(path)\n",
    "    lists=[]\n",
    "    for i in range(len(list)):\n",
    "        fname=list[i]\n",
    "        date=fname[:6]\n",
    "        if int(date)>=date0 and int(date)<=date1:\n",
    "            lists.append(fname)\n",
    "    return lists\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "def read_pan_tick(path,yy,mm,dd):#テキストファイルの読み込み\n",
    "    with open(path,'r',encoding='UTF-8') as f:\n",
    "        line=f.readline()\n",
    "        da=[]\n",
    "        price=[]\n",
    "        i=0\n",
    "        while line:\n",
    "            elements=line.rstrip()\n",
    "            e=elements.split()\n",
    "            hhmmss=e[0]\n",
    "            hms=hhmmss.split(':')#hms[0]:hour;hms[1]:minute;hms[2]:second \n",
    "            da00=datetime(yy,mm,dd)\n",
    "            if da00.weekday()==0: #月曜=0          \n",
    "                da00=datetime(yy,mm,dd)+timedelta(days=-3)\n",
    "            else:\n",
    "                da00=datetime(yy,mm,dd)+timedelta(days=-1)\n",
    "            if int(hms[0])>=16 and int(hms[0])<=23: #16:30 - 23:59:99\n",
    "                pass\n",
    "            if int(hms[0])>=0 and int(hms[0])<=3: #00:00 - 3:00\n",
    "                da00=da00+timedelta(days=1)\n",
    "            if int(hms[0])>=9 and int(hms[0])<=15: #09:00 - 15:00\n",
    "                da00=datetime(yy,mm,dd)\n",
    "            dd0=da00.day\n",
    "            mm0=da00.month\n",
    "            da0=datetime(yy,mm0,dd0,int(hms[0]),int(hms[1]),int(hms[2]))\n",
    "            da.append(da0)\n",
    "            price.append([])\n",
    "            price[i].append(int(e[1]))\n",
    "            price[i].append(int(e[2]))\n",
    "            i+=1\n",
    "            line=f.readline()#テキストファイルの行の読み込み\n",
    "    ts=pd.DataFrame(price,index=da,columns=[\"price\",\"volume\"])#daをインデックスに設定。\n",
    "    ts.index.name='date'#インデックスに名前を付与する。\n",
    "    return ts\n",
    "\n",
    "def file_concat_pan_tick(path,date1,date0):#date1、date2で指定された日時の間のデータをdata2からdeta1まで垂直に結合する。\n",
    "    dates=dir_file_get(path,date1,date0)\n",
    "    for i in range(len(dates)):\n",
    "        date=dates[i]\n",
    "        fname=path+date\n",
    "        date0=date[:6]\n",
    "        yy,mm,dd=yymmdd_split(date0)#ファイルの年、月、日を取得\n",
    "        if i==0:\n",
    "            ts=read_pan_tick(fname,yy,mm,dd)\n",
    "        else:\n",
    "            ts0=read_pan_tick(fname,yy,mm,dd)\n",
    "            ts=pd.concat([ts,ts0])\n",
    "    return ts\n",
    "\n",
    "def file_conv_tick_2session(fname,ts):#ティックデータを４本値に変換、csvファイルとして保存\n",
    "    nss_flg=False #夜間立会のフラグ\n",
    "    dss_flg=False #日中立会のフラグ\n",
    "    dat=[]\n",
    "    trade=[]\n",
    "    yy=mm=dd=0\n",
    "    o=h=l=p=int(ts.iloc[0].price)\n",
    "    j=0\n",
    "    v_s=tv_s=0\n",
    "    #関数内の関数の定義--------------------------------------------------\n",
    "    def max_min_volume_value(i,h,l,v_s,tv_s):#高値、安値、取引高、売買代金\n",
    "        p=int(ts.iloc[i].price)\n",
    "        v=int(ts.iloc[i].volume)\n",
    "        h=max(h,p)\n",
    "        l=min(l,p)\n",
    "        v_s+=v\n",
    "        tv_s+=v*p\n",
    "        return p,h,l,v_s,tv_s\n",
    "    def dat_trade_append(j,da0,o,h,l,c,v_s,tv_s):#情報の追加\n",
    "        dat.append(da0)\n",
    "        trade.append([])\n",
    "        trade[j].append(o)\n",
    "        trade[j].append(h)\n",
    "        trade[j].append(l)\n",
    "        trade[j].append(c)\n",
    "        trade[j].append(v_s)\n",
    "        trade[j].append(tv_s)\n",
    "        v_s=0\n",
    "        tv_s=0\n",
    "        j+=1\n",
    "        return dat,trade,v_s,tv_s,j\n",
    "    def init_trade(i,da):#データの初期化\n",
    "        o=int(ts.iloc[i].price)\n",
    "        h=o\n",
    "        l=o\n",
    "        yy=da.year[0]\n",
    "        mm=da.month[0]\n",
    "        dd=da.day[0]\n",
    "        return o,h,l,yy,mm,dd\n",
    "    #メインループ---------------------------------------------------------\n",
    "    for i in range(len(ts)):\n",
    "        da=ts[i:i+1].index\n",
    "        t=ts[i:i+1].index.time\n",
    "        if t==time(16,30) and dss_flg:#日中立会のデータの更新\n",
    "            dss_flg=False\n",
    "            da0=datetime(yy,mm,dd,9,0)\n",
    "            sat,trade,v_s,tv_s,j=dat_trade_append(j,da0,o,h,l,c,v_s,tv_s)\n",
    "        if t==time(16,30) and not nss_flg:#夜間立会開始\n",
    "            dss_flg=False\n",
    "            o,h,l,yy,mm,dd=init_trade(i,da)\n",
    "            nss_flg=True\n",
    "        if t>=time(16,30) and t<=time(23,59,59) and nss_flg:#夜間立会、当日ザラバ取引\n",
    "            p,h,l,v_s,tv_s=max_min_volume_value(i,h,l,v_s,tv_s)\n",
    "        if t>=time(0,0) and t<=time(2,55) and nss_flg:#夜間立会、翌日ザラバ取引\n",
    "            p,h,l,v_s,tv_s=max_min_volume_value(i,h,l,v_s,tv_s)\n",
    "        if t==time(3,0) and nss_flg:#夜間立会、翌日板寄せ取引\n",
    "            c,h,l,v_s,tv_s=max_min_volume_value(i,h,l,v_s,tv_s)\n",
    "        if t<=time(9,0,2) and t>=time(9,0) and nss_flg:#夜間立会のデータの更新\n",
    "            nss_flg=False\n",
    "            da0=datetime(yy,mm,dd,16,30)\n",
    "            sat,trade,v_s,tv_s,j=dat_trade_append(j,da0,o,h,l,c,v_s,tv_s)\n",
    "            #print(da[0],t,da0)\n",
    "        if t<=time(9,0,2) and t>=time(9,0,0) and not dss_flg:#日中立会の開始\n",
    "            o,h,l,yy,mm,dd=init_trade(i,da)\n",
    "            dss_flg=True\n",
    "        if t>=time(9,0) and t<=time(15,10) and dss_flg:#日中立会のザラバと寄り板寄せ取引\n",
    "            p,h,l,v_s,tv_s=max_min_volume_value(i,h,l,v_s,tv_s)\n",
    "        if t==time(15,15) and dss_flg:#日中取引の引け板寄せ取引\n",
    "            c,h,l,v_s,tv_s=max_min_volume_value(i,h,l,v_s,tv_s)\n",
    "    if t==time(15,15) and dss_flg:#日中取引のデータの更新\n",
    "        da0=datetime(yy,mm,dd,9,0)\n",
    "        sat,trade,v_s,tv_s,j=dat_trade_append(j,da0,o,h,l,c,v_s,tv_s)\n",
    "        #print(da[0],t,da0)\n",
    "  \n",
    "    tsnew=pd.DataFrame(trade,index=dat,columns=['Open','High','Low','Close','Volume','Value'])\n",
    "    tsneｗ.index.name='Date'\n",
    "    tsnew.to_csv(fname)\n",
    "    return tsnew\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7106572\n",
      "1:41:28.389305\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    t1=datetime.now()\n",
    "    path = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\1509\\\\\"\n",
    "    path2 = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\\"\n",
    "    fname= \"n225m1509.csv\"\n",
    "    entry=150612\n",
    "    exit=150910\n",
    "    pan=file_concat_pan_tick(path,exit,entry)\n",
    "    fname=path2+fname\n",
    "    pan2=file_conv_tick_2session(fname,pan)\n",
    "    print(len(pan))\n",
    "t2=datetime.now()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4062659\n",
      "0:57:52.967065\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, date,timedelta\n",
    "from datetime import time\n",
    "if __name__ == \"__main__\":\n",
    "    t1=datetime.now()\n",
    "    path = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\1506\\\\\"\n",
    "    path2 = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\\"\n",
    "    fname= \"n225m1506.csv\"\n",
    "    entry=150313\n",
    "    exit=150612\n",
    "    pan=file_concat_pan_tick(path,exit,entry)\n",
    "    fname=path2+fname\n",
    "    pan2=file_conv_tick_2session(fname,pan)\n",
    "\n",
    "    print(len(pan))\n",
    "t2=datetime.now()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3691888\n",
      "0:52:54.423586\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    t1=datetime.now()\n",
    "    path = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\1503\\\\\"\n",
    "    path2 = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\\"\n",
    "    fname= \"n225m1503.csv\"\n",
    "    entry=141212\n",
    "    exit=150312\n",
    "    pan=file_concat_pan_tick(path,exit,entry)\n",
    "    fname=path2+fname\n",
    "    pan2=file_conv_tick_2session(fname,pan)\n",
    "\n",
    "    print(len(pan))\n",
    "t2=datetime.now()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5110180\n",
      "1:12:50.259853\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    t1=datetime.now()\n",
    "    path = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\1512\\\\\"\n",
    "    path2 = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\\"\n",
    "    fname= \"n225m1512.csv\"\n",
    "    entry=150911\n",
    "    exit=151210\n",
    "    pan=file_concat_pan_tick(path,exit,entry)\n",
    "    fname=path2+fname\n",
    "    pan2=file_conv_tick_2session(fname,pan)\n",
    "\n",
    "    print(len(pan))\n",
    "t2=datetime.now()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130111\n",
      "0:16:04.465369\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    t1=datetime.now()\n",
    "    path = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\1603\\\\\"\n",
    "    path2 = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\\"\n",
    "    fname= \"n225m1603.csv\"\n",
    "    entry=151211\n",
    "    exit=160104\n",
    "    pan=file_concat_pan_tick(path,exit,entry)\n",
    "    fname=path2+fname\n",
    "    pan2=file_conv_tick_2session(fname,pan)\n",
    "\n",
    "    print(len(pan))\n",
    "t2=datetime.now()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.022255\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    t1=datetime.now()\n",
    "    path2 = \"c:\\\\users\\\\moriya\\\\documents\\\\database\\\\pan\\\\n225\\\\TICK\\\\1001\\\\\"\n",
    "    fname=[\"n225m1503.csv\",\"n225m1506.csv\",\"n225m1509.csv\",\"n225m1512.csv\",\"n225m1603.csv\"]\n",
    "    ts=pd.read_csv(path2+fname[0],index_col=0,parse_dates=True)\n",
    "    for i in range(1,len(fname)):\n",
    "        pathfname=path2+fname[i]\n",
    "        ts0=pd.read_csv(pathfname,index_col=0,parse_dates=True)\n",
    "        ts=pd.concat([ts,ts0])\n",
    "    pathfname=path2+'nikkei225fm_2_2015.csv'#書籍のファイル名と違いますが、こちらでプログラムが動きます。\n",
    "    ts.to_csv(pathfname)\n",
    "    #print(ts)\n",
    "t2=datetime.now()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "def datetime_parser(str_date):\n",
    "    try:\n",
    "        return datetime.strptime(str_date,'%Y-%m-%d')\n",
    "    except(Exception):    \n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import urllib.request\n",
    "import codecs\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xxx_retrieve_2session(url,path):\n",
    "    urllib.request.urlretrieve(url, path)\n",
    "    fut=codecs.open(path,'r','shift_jis')\n",
    "    f=[]\n",
    "    da=[]\n",
    "    i=0\n",
    "    for line in fut:            \n",
    "        a=line.split(',')\n",
    "        b=a[0]\n",
    "        if datetime_parser(b):\n",
    "            y=int(b[:4])\n",
    "            m=int(b[5:7])\n",
    "            d=int(b[8:])\n",
    "            x=a[1]\n",
    "            if x==(u'日中'):\n",
    "                d=datetime(y,m,d,9,0)\n",
    "            else:\n",
    "                if x==(u'夜間'):\n",
    "                    d=datetime(y,m,d,16,30)\n",
    "            da.append(d)\n",
    "            f.append([])\n",
    "            for j in range(2,7):\n",
    "                f[i].append(a[j])\n",
    "            f[i].append(a[7][:-2])\n",
    "            i+=1\n",
    "    f1=pd.DataFrame(f,columns=['Open','High','Low','Close','Volume','Value'],index=da)\n",
    "    f1.index.name='Date'\n",
    "    f1=f1.sort_index()\n",
    "    f1.to_csv(path)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9030c2019f3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://xxx.com/futures/F102-0001/1d/2015?download=csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"c:/users/xxx/documents/ipython notebooks/temp.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mn225fm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxxx_retrieve_2session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(n225fm)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "rl = \"http://xxx.com/futures/F102-0001/1d/2015?download=csv\"\n",
    "path = \"c:/users/xxx/documents/ipython notebooks/temp.csv\"\n",
    "n225fm=xxx_retrieve_2session(url,path).dropna()\n",
    "#print(n225fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
